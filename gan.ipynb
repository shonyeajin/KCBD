{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gan",
      "provenance": [],
      "authorship_tag": "ABX9TyO2UL4wP6b0CHOXLwiRJTVK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shonyeajin/KCBD/blob/main/gan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "생성자"
      ],
      "metadata": {
        "id": "R3U6uYegB9eo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "W5wJ9RQr6r_e"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras import layers\n",
        "import numpy as np\n",
        "\n",
        "latent_dim=32\n",
        "height=32\n",
        "width=32\n",
        "channels=3\n",
        "\n",
        "generator_input=keras.Input(shape=(latent_dim,))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=layers.Dense(128*16*16)(generator_input)\n",
        "x=layers.LeakyReLU()(x)\n",
        "x=layers.Reshape((16,16,128))(x)\n",
        "\n",
        "x=layers.Conv2D(256,5, padding='same')(x)\n",
        "x=layers.LeakyReLU()(x)\n",
        "\n",
        "x=layers.Conv2DTranspose(256, 4, strides=2, padding='same')(x)\n",
        "x=layers.LeakyReLU()(x)"
      ],
      "metadata": {
        "id": "MYqMLkrLAawh"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=layers.Conv2D(256, 5,padding='same')(x)\n",
        "x=layers.LeakyReLU()(x)\n",
        "x=layers.Conv2D(256, 5,padding='same')(x)\n",
        "x=layers.LeakyReLU()(x)\n",
        "\n",
        "x=layers.Conv2D(channels, 7, activation='tanh', padding='same')(x)\n",
        "generator=keras.models.Model(generator_input, x)\n",
        "generator.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hyySJo9TBRoL",
        "outputId": "4650ce44-4000-49f1-a329-0cac3e08584c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_6 (InputLayer)        [(None, 32)]              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 32768)             1081344   \n",
            "                                                                 \n",
            " leaky_re_lu_17 (LeakyReLU)  (None, 32768)             0         \n",
            "                                                                 \n",
            " reshape_1 (Reshape)         (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " conv2d_16 (Conv2D)          (None, 16, 16, 256)       819456    \n",
            "                                                                 \n",
            " leaky_re_lu_18 (LeakyReLU)  (None, 16, 16, 256)       0         \n",
            "                                                                 \n",
            " conv2d_transpose_1 (Conv2DT  (None, 32, 32, 256)      1048832   \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " leaky_re_lu_19 (LeakyReLU)  (None, 32, 32, 256)       0         \n",
            "                                                                 \n",
            " conv2d_17 (Conv2D)          (None, 32, 32, 256)       1638656   \n",
            "                                                                 \n",
            " leaky_re_lu_20 (LeakyReLU)  (None, 32, 32, 256)       0         \n",
            "                                                                 \n",
            " conv2d_18 (Conv2D)          (None, 32, 32, 256)       1638656   \n",
            "                                                                 \n",
            " leaky_re_lu_21 (LeakyReLU)  (None, 32, 32, 256)       0         \n",
            "                                                                 \n",
            " conv2d_19 (Conv2D)          (None, 32, 32, 3)         37635     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,264,579\n",
            "Trainable params: 6,264,579\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "판별자"
      ],
      "metadata": {
        "id": "_6pJdrFkCAr2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator_input=layers.Input(shape=(height, width, channels))\n",
        "x= layers.Conv2D(128, 3)(discriminator_input)\n",
        "x=layers.LeakyReLU()(x)\n",
        "x=layers.Conv2D(128, 4, strides=2)(x)\n",
        "x=layers.LeakyReLU()(x)\n",
        "x=layers.Conv2D(128, 4, strides=2)(x)\n",
        "x=layers.LeakyReLU()(x)\n",
        "x=layers.Conv2D(128, 4, strides=2)(x)\n",
        "x=layers.LeakyReLU()(x)\n",
        "\n",
        "x=layers.Dropout(0.4)(x)\n",
        "\n",
        "x=layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "discriminator=keras.models.Model(discriminator_input, x)\n",
        "discriminator.summary()\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "discriminator_optimizer=tf.keras.optimizers.RMSprop(lr=0.0008, clipvalue=1.0, decay=1e-8)\n",
        "discriminator.compile(optimizer=discriminator_optimizer, loss='binary_crossentropy')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Ab5y6xhB0sM",
        "outputId": "597aab77-5bb1-4bbd-dc40-6b3562f88b8d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_7 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " conv2d_20 (Conv2D)          (None, 30, 30, 128)       3584      \n",
            "                                                                 \n",
            " leaky_re_lu_22 (LeakyReLU)  (None, 30, 30, 128)       0         \n",
            "                                                                 \n",
            " conv2d_21 (Conv2D)          (None, 14, 14, 128)       262272    \n",
            "                                                                 \n",
            " leaky_re_lu_23 (LeakyReLU)  (None, 14, 14, 128)       0         \n",
            "                                                                 \n",
            " conv2d_22 (Conv2D)          (None, 6, 6, 128)         262272    \n",
            "                                                                 \n",
            " leaky_re_lu_24 (LeakyReLU)  (None, 6, 6, 128)         0         \n",
            "                                                                 \n",
            " conv2d_23 (Conv2D)          (None, 2, 2, 128)         262272    \n",
            "                                                                 \n",
            " leaky_re_lu_25 (LeakyReLU)  (None, 2, 2, 128)         0         \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 2, 2, 128)         0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 2, 2, 1)           129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 790,529\n",
            "Trainable params: 790,529\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "적대적 네트워크"
      ],
      "metadata": {
        "id": "zN6BumjeHnT5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator.trainable=False\n",
        "\n",
        "gan_input=keras.Input(shape=(latent_dim,))\n",
        "gan_output=discriminator(generator(gan_input))\n",
        "gan=keras.models.Model(gan_input, gan_output)\n",
        "\n",
        "gan_optimizer=tf.keras.optimizers.RMSprop(lr=0.0004, clipvalue=1.0, decay=1e-8)\n",
        "gan.compile(optimizer=gan_optimizer, loss='binary_crossentropy')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FG_1f7cmHTDH",
        "outputId": "af822c86-3b8f-4ffa-d6c5-619f07663655"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DCGAN 훈련"
      ],
      "metadata": {
        "id": "A9SF5AyJIc-j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from keras.preprocessing import image\n",
        "\n",
        "(x_train, y_train),(_,_)=keras.datasets.cifar10.load_data()\n",
        "\n",
        "x_train=x_train[y_train.flatten()==6]\n",
        "\n",
        "x_train=x_train.reshape(\n",
        "    (x_train.shape[0],)+(height,width, channels)).astype('float32')/255.\n",
        "\n",
        "iterations=10000\n",
        "batch_size=20\n",
        "save_dir='./datasets/gan_images/'\n",
        "if not os.path.exists(save_dir):\n",
        "  os.mkdir(save_dir)"
      ],
      "metadata": {
        "id": "EROGIzTMH9do"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start=0\n",
        "for step in range(iterations):\n",
        "  random_latent_vectors=np.random.normal(size=(batch_size,latent_dim))\n",
        "  generated_images=generator.predict(random_latent_vectors)\n",
        "\n",
        "  stop=start+batch_size\n",
        "  real_images=x_train[start:stop]\n",
        "  combined_images=np.concatenate([generated_images, real_images])\n",
        "\n",
        "  labels=np.concatenate([np.ones((batch_size,1)),np.zeros((batch_size, 1))])\n",
        "\n",
        "  labels+=0.05*np.random.random(labels.shape)\n",
        "  d_loss=discriminator.train_on_batch(combined_images, labels)\n",
        "\n",
        "  random_latent_vectors=np.random.normal(size=(batch_size, latent_dim))\n",
        "\n",
        "  misleading_targets=np.zeros((batch_size,1))\n",
        "  \n",
        "  a_loss=gan.train_on_batch(random_latent_vectors, misleading_targets)\n",
        "\n",
        "  start+=batch_size\n",
        "  if start> len(x_train)-batch_size:\n",
        "    start=0\n",
        "  if step%100==0:\n",
        "    gan.save_weights('gan.h5')\n",
        "\n",
        "    print('스텝 %s에서 판별자 손실: %s'%(step, d_loss))\n",
        "    print('스텝 %s에서 적대적 손실: %s'%(step, a_loss))\n",
        "\n",
        "    img=image.array_to_img(generated_images[0]*255., scale=False)\n",
        "    img.save(os.path.join(save_dir, 'generated_frog'+ str(step)+'.png'))\n",
        "\n",
        "    img=image.array_to_img(real_images[0]*255., scale=False)\n",
        "    img.save(os.path.join(save_dir, 'real_frog'+str(step)+'.png'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CVg0uGp1JW5a",
        "outputId": "d201b1f9-aae1-4786-86f7-2847f7329536"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-9a131c001eb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0mlabels\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m   \u001b[0md_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0mrandom_latent_vectors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[1;32m   1898\u001b[0m                                                     class_weight)\n\u001b[1;32m   1899\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1900\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1902\u001b[0m     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1130\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 810, in train_step\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 141, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 245, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 1807, in binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"/usr/local/lib/python3.7/dist-packages/keras/backend.py\", line 5158, in binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(labels=target, logits=output)\n\n    ValueError: `logits` and `labels` must have the same shape, received ((40, 2, 2, 1) vs (40, 1)).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "nIQRBYOrTnvt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}